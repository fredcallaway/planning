{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools as it\n",
    "from itertools import product\n",
    "from collections import Counter, defaultdict, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import copy\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=1.3)\n",
    "\n",
    "from agents import Agent\n",
    "from evaluation import get_util\n",
    "from joblib import Parallel, delayed\n",
    "# from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import ipyparallel as ipp \n",
    "# rc = ipp.Client(profile='default', cluster_id='')\n",
    "# ipp.register_joblib_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mouselab import MouselabEnv\n",
    "from distributions import Categorical, Normal\n",
    "\n",
    "def make_envs(cost=1.00, n=100, seed=None,variance_structure=\"constant_high\",branching=[4,1,2]):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    depth = len(branching)\n",
    "    \n",
    "    if variance_structure is \"constant_high\":\n",
    "        sigmas = np.concatenate( (np.array([0]),20*np.ones(depth)))\n",
    "    if variance_structure is \"increasing\":\n",
    "        sigmas = [0, 2, 4, 20]\n",
    "    if variance_structure is \"decreasing\":\n",
    "        sigmas = [0,20,4,2]\n",
    "    if variance_structure is \"constant_low\":\n",
    "        sigmas = np.concatenate( (np.array([0]),3*np.ones(depth)))\n",
    "        \n",
    "    def reward(depth):\n",
    "        if depth > 0:\n",
    "            return Normal(0, sigmas[depth]).to_discrete(6)\n",
    "        return 0.\n",
    "\n",
    "    envs = [MouselabEnv.new_symmetric(branching, reward)\n",
    "            for _ in range(n)]\n",
    "    for env in envs:\n",
    "        env.cost=-cost\n",
    "    \n",
    "    return envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = 1\n",
    "envs = make_envs(cost,10,None,\"increasing\",branching=[2,2])\n",
    "env = envs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [1, 3], [4, 5], [4, 6]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, Cat, Cat, Cat, Cat, Cat, Cat)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4], [2, 3], [], [], [5, 6], [], []]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fancy initialization function, but doesn't seem necessary\n",
    "# simpler version built into the class\n",
    "def build_path(r):   \n",
    "    if env.tree[r] == []:\n",
    "        return ([[]], [0])\n",
    "    paths = []\n",
    "    path_moves = []\n",
    "    for n in env.tree[r]:\n",
    "        new_paths, new_path_moves = build_path(n)\n",
    "        for i in range(len(new_paths)):\n",
    "            new_paths[i].insert(0,n)\n",
    "            new_move = int(hasattr(env._state[n],'sample'))\n",
    "            path_moves.append(new_path_moves[i]+new_move)\n",
    "            paths.append(new_paths[i])\n",
    "    return (paths,path_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def option_util(x,sigma):\n",
    "    return sigma*scipy.stats.norm.pdf(x/sigma) - np.abs(x)*scipy.stats.norm.cdf(-np.abs(x)/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_options(env):\n",
    "    paths = env.paths #list of all paths\n",
    "    avail_moves = [0,]*len(paths) #list of moves available in each path\n",
    "    path_obs = [] #value of observed nodes in each path\n",
    "    path_nodes = [] #the unobserved nodes of each path\n",
    "    path_stds = [] #the std deviation of the unobserved nodes of each path\n",
    "    \n",
    "    options = [] #list of all options\n",
    "    option_utils = [] #list of the utility of each option\n",
    "    \n",
    "    for i in range(len(paths)):\n",
    "        stds = []\n",
    "        nodes = []\n",
    "        obs = 0\n",
    "        \n",
    "        for node in paths[i]:\n",
    "            if hasattr(env._state[node],'sample'):\n",
    "                stds.append(env._state[node].var())\n",
    "                nodes.append(node)\n",
    "                avail_moves[i] += 1\n",
    "            else:\n",
    "                obs += env._state[node]\n",
    "                \n",
    "        path_obs.append(obs)\n",
    "        path_stds.append(stds)\n",
    "        path_nodes.append(nodes)\n",
    "        \n",
    "        for j in range(avail_moves[i]):\n",
    "            options.append((i,j+1))\n",
    "    max_obs = np.max(path_obs)\n",
    "    \n",
    "    for option in options:\n",
    "        path, obs = option\n",
    "        option_utils.append(option_util(path_obs[path]-max_obs,np.sqrt(np.sum(np.sort(path_stds[path])[::-1][:obs]))) + obs*env.cost)\n",
    "    \n",
    "    return options, option_utils, path_nodes, path_stds, path_obs, avail_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_option_moves(env):\n",
    "    options, option_utils, path_nodes, path_stds, path_obs, avail_moves = get_all_options(env)\n",
    "    \n",
    "    #c is for chosen\n",
    "    cpath, cobs = options[np.random.choice(np.arange(len(options))[option_utils == np.max(option_utils)])]\n",
    "    cpath_stds = np.array(path_stds[cpath])[:cobs]\n",
    "    cpath_nodes = np.array(path_nodes[cpath])[:cobs]\n",
    "    b = np.random.random(cpath_nodes.size)\n",
    "    \n",
    "    return cpath_nodes[np.lexsort((b,cpath_stds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5064855900000111\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.process_time()\n",
    "for i in range(1000):\n",
    "#     print(get_options(env))\n",
    "    pick_option_moves(env)\n",
    "elapsed =time.process_time() - t \n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_option_insts(path_nodes,path_stds,n_obs):\n",
    "    insts = [[]]\n",
    "    n_remaining_obs = n_obs\n",
    "\n",
    "    vals, inverse, count = np.unique(path_stds, return_inverse=True,\n",
    "                                  return_counts=True)\n",
    "    rows, cols = np.where(inverse == np.arange(len(vals))[:, np.newaxis])\n",
    "    _, inverse_rows = np.unique(rows, return_index=True)\n",
    "    res = np.split(cols, inverse_rows[1:])\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        new_insts = []\n",
    "\n",
    "        n_new_nodes = len(res[-i-1])\n",
    "        if n_new_nodes < n_remaining_obs:\n",
    "            n_remaining_obs -= n_new_nodes\n",
    "        else:\n",
    "            n_new_nodes = n_remaining_obs\n",
    "            n_remaining_obs = 0  \n",
    "\n",
    "        for new_nodes in it.permutations(res[-i-1],n_new_nodes):\n",
    "            for inst in insts:\n",
    "                new_insts.append(inst + list(np.array(path_nodes)[list(new_nodes)]))\n",
    "        insts = new_insts\n",
    "        if n_remaining_obs == 0:\n",
    "            break\n",
    "            \n",
    "    return insts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18115845400006947\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "path_stds= [10.00,10.00,9,8.0,8,7,7,6]\n",
    "path_nodes = np.arange(len(path_stds))\n",
    "t = time.process_time()\n",
    "for i in range(1000):\n",
    "#     print(get_options(env))\n",
    "    all_option_insts(path_nodes,path_stds,6)\n",
    "elapsed =time.process_time() - t \n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5],\n",
       " [1, 0, 2, 3, 4, 5],\n",
       " [0, 1, 2, 4, 3, 5],\n",
       " [1, 0, 2, 4, 3, 5],\n",
       " [0, 1, 2, 3, 4, 6],\n",
       " [1, 0, 2, 3, 4, 6],\n",
       " [0, 1, 2, 4, 3, 6],\n",
       " [1, 0, 2, 4, 3, 6]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_stds= [10.00,10.00,9,8.0,8,7,7,6]\n",
    "path_nodes = np.arange(len(path_stds))\n",
    "all_option_insts(path_nodes,path_stds,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following equation gives the likelihood of a click sequence in this model:\n",
    "\n",
    "$$ l(C) = \\sum_{O \\in \\mathcal{O}(C)} l(O)$$\n",
    "\n",
    "where $C$ is a click sequence, and $\\mathcal{O}(C)$ is the set of option sequences that $C$ could parse into. To get the likelihood of an option sequence, we use the following equation:\n",
    "\n",
    "$$ l(O) = \\prod_{o \\in O} \\mathbb{P}_{DC}(o) $$\n",
    "\n",
    "where $\\mathbb{P}_{DC}(o)$ is the probability of a given option in our model. We assume a generative model that picks a random move with probability $p_r$, or otherwise picks from one of the available options under the directed cognition model. This gives us the following equation: \n",
    "\n",
    "$$\\mathbb{P}_{DC}(o) = (1-p_r)*s(o)+p_r*\\alpha$$ \n",
    "\n",
    "$s(o)$ is the softmax probability of our option among all available directed cognition options, which, for a given temperature parameter $t = \\frac{1}{\\beta}$ is equal to:\n",
    "\n",
    "$$ s(o)= \\frac{e^{\\beta v(o)}}{\\sum_{o'} e^{\\beta v(o')}} $$\n",
    "\n",
    "where $v(o)$ is the value of an option using the directed cognition model. We define $\\alpha$ as the probability that an option in the sequence would have been generated by the error process, and it is defined as:\n",
    "\n",
    "$$\\alpha = \\prod_{k = 1}^ \\text{length(o)} \\frac{1}{n_{ac}-k+1}$$\n",
    "\n",
    "where $n_{ac}$ is the number of available clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = np.array([[np.prod([1/(nac-k+1) for k in range(1,obs+1)]) for obs in range(1,min(len(env.paths[0]),nac)+1)] for nac in range(1,13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000001"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod([1/(10-k+1) for k in range(1,1+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_options(env,click_sequence,t=1,p_rand=0.0001):\n",
    "    if click_sequence == []:\n",
    "        return True, [[]], [1]\n",
    "    option_insts = dict() #list of all possible option instantiations\n",
    "    option_seqs = []\n",
    "    likelihoods = []\n",
    "    done = False\n",
    "    \n",
    "    paths = env.paths\n",
    "    options, option_utils, path_nodes, path_stds, path_obs, avail_moves = get_all_options(env)\n",
    "    \n",
    "    for option in options:\n",
    "        path, obs = option\n",
    "        option_insts[option] = all_option_insts(path_nodes[path],path_stds[path],obs)\n",
    "        \n",
    "    #single click options\n",
    "    sc_opt = (-1,1)\n",
    "    options.append(sc_opt)\n",
    "    option_utils.append(-np.inf)\n",
    "    option_utils = np.array(option_utils)\n",
    "    option_insts[sc_opt] = [[a] for a in env.actions(env._state)]\n",
    "    n_available_clicks = len(option_insts[sc_opt])-1\n",
    "        \n",
    "    for i in range(1,min(len(paths[0]),len(click_sequence))+1):  \n",
    "        for j in range(len(options)):\n",
    "            option = options[j]\n",
    "            for inst in option_insts[option]:      \n",
    "                if np.array_equal(click_sequence[:i],inst):\n",
    "                    copy_env = copy.deepcopy(env)                   \n",
    "                    for a in click_sequence[:i]:\n",
    "                        copy_env._step(a)\n",
    "                        \n",
    "                    will_done, remaining, rem_likelihoods = parse_options(copy_env,click_sequence[i:])\n",
    "                    done = done or will_done\n",
    "                    \n",
    "                    if done:\n",
    "                        for k in range(len(remaining)): \n",
    "                            latter = remaining[k]\n",
    "                            option_seqs.append([option]+latter)    \n",
    "                            l_opt_seq = (1-p_rand)*np.exp(1/t*option_utils[j])/np.sum(np.exp(1/t*option_utils[:-1]))\n",
    "                            l_opt_seq += p_rand*np.prod([1/(n_available_clicks-k+1) for k in range(1,option[1]+1)])\n",
    "#                             l_opt_seq += p_rand*alphas[n_available_clicks-1][option[1]-1]\n",
    "                            l_opt_seq *= rem_likelihoods[k]\n",
    "                            likelihoods.append(l_opt_seq)\n",
    "    \n",
    "    return done, option_seqs, likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_options_combined(env,click_sequence,temps=np.logspace(-3,1,50),p_errs=np.linspace(0,0.25,25)):\n",
    "    \n",
    "    #count things\n",
    "    n_temps = len(temps)\n",
    "    n_p_errs = len(p_errs)\n",
    "    \n",
    "    #base case\n",
    "    if click_sequence == []:\n",
    "        return True, [[]], [np.ones((n_temps,n_p_errs))]\n",
    "    \n",
    "    #get the info you'll need for parsing\n",
    "    paths = env.paths\n",
    "    options, option_utils, path_nodes, path_stds, path_obs, avail_moves = get_all_options(env)\n",
    "    \n",
    "    option_insts = dict() #list of all possible option instantiations\n",
    "    for option in options:\n",
    "        path, obs = option\n",
    "        option_insts[option] = all_option_insts(path_nodes[path],path_stds[path],obs)\n",
    "    \n",
    "    #set up your return values\n",
    "    option_seqs = []\n",
    "    likelihoods = []\n",
    "    done = False\n",
    "        \n",
    "    #single click options\n",
    "    sc_opt = (-1,1)\n",
    "    options.append(sc_opt)\n",
    "    option_utils.append(-np.inf)\n",
    "    option_utils = np.array(option_utils)\n",
    "    option_insts[sc_opt] = [[a] for a in env.actions(env._state)]\n",
    "    n_available_clicks = len(option_insts[sc_opt])-1\n",
    "    \n",
    "    #parsing\n",
    "    for i,j in product(range(1,min(len(paths[0]),len(click_sequence))+1),range(len(options))):  \n",
    "            option = options[j]\n",
    "            for inst in option_insts[option]:      \n",
    "                if np.array_equal(click_sequence[:i],inst):\n",
    "                    copy_env = copy.deepcopy(env)                   \n",
    "                    for a in click_sequence[:i]:\n",
    "                        copy_env._step(a)\n",
    "                        \n",
    "                    will_done, remaining, rem_likelihoods = parse_options_combined(copy_env,click_sequence[i:])\n",
    "                    done = done or will_done\n",
    "                    \n",
    "                    if done:\n",
    "                        for k in range(len(remaining)): \n",
    "                            latter = remaining[k]\n",
    "                            option_seqs.append([option]+latter)\n",
    "                            \n",
    "                            for l,m in product(range(n_temps),range(n_p_errs)):\n",
    "                                l_opt_seq = np.zeros((n_temps,n_p_errs))\n",
    "                                t = temps[l]\n",
    "                                p_err = p_errs[m]\n",
    "                                l_opt_seq[l,m] = (1-p_err)*np.exp(1/t*option_utils[j])/np.sum(np.exp(1/t*option_utils[:-1]))\n",
    "                                l_opt_seq[l,m] += p_err*np.prod([1/(n_available_clicks-k+1) for k in range(1,option[1]+1)])\n",
    "                                l_opt_seq *= rem_likelihoods[k][l,m]\n",
    "                            \n",
    "                                likelihoods.append(l_opt_seq)\n",
    "    return done, option_seqs, likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_env(mu=0, sigma=5, quantization=4, cost=1.00, seed=None, branching=[3,1,2], **kwargs):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def reward(depth):\n",
    "        if depth > 0:\n",
    "            x = np.array([-2,-1,1,2])\n",
    "            return Categorical(mu + sigma * x)\n",
    "        return 0.\n",
    "\n",
    "    return MouselabEnv.new_symmetric(branching, reward, cost=cost, **kwargs)\n",
    "\n",
    "env = make_env(ground_truth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 participants\n"
     ]
    }
   ],
   "source": [
    "from analysis_utils import *\n",
    "VERSION = 'c1.1'\n",
    "exp_data = get_data(VERSION, '../experiment/data')\n",
    "\n",
    "pdf = exp_data['participants']\n",
    "pdf = pdf.loc[pdf.completed].copy()\n",
    "print(f'{len(pdf)} participants')\n",
    "complete = list(pdf.index)\n",
    "\n",
    "def extract(q):\n",
    "    return list(map(int, q['click']['state']['target']))\n",
    "\n",
    "mdf = exp_data['mouselab-mdp'].query('pid == @complete').copy()\n",
    "mdf['clicks'] = mdf.queries.apply(extract)\n",
    "mdf['n_clicks'] = mdf.clicks.apply(len)\n",
    "mdf['thinking'] = mdf['rt'].apply(get(0, default=0))\n",
    "\n",
    "tdf = mdf.query('block == \"test\"').copy()\n",
    "tdf.trial_index -= tdf.trial_index.min()\n",
    "tdf.trial_index = tdf.trial_index.astype(int)\n",
    "tdf.trial_id = tdf.trial_id.astype(int)\n",
    "\n",
    "# pdf['total_time'] = exp_data['survey'].time_elapsed / 60000\n",
    "\n",
    "pdf['n_clicks'] = tdf.groupby('pid').n_clicks.mean()\n",
    "pdf['score'] = tdf.groupby('pid').score.mean()\n",
    "pdf['thinking'] = mdf.groupby('pid').thinking.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluding 9 out of 60 partipicants\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def excluded_pids():\n",
    "    sdf = exp_data['survey-multi-choice'].query('pid == @complete').copy()\n",
    "    sdf = pd.DataFrame(list(sdf.responses), index=sdf.index)\n",
    "    correct = pd.Series(['-$10 to $10', '$1', '1 cent for every $1 you make in the game'])\n",
    "    fail_quiz = (sdf != correct).sum(axis=1) > 1\n",
    "    no_click = mdf.query('block == \"train_inspector\"').groupby('pid').n_clicks.sum() == 0\n",
    "    return fail_quiz | no_click\n",
    "\n",
    "exclude = excluded_pids()\n",
    "tdf['exclude'] = list(exclude.loc[tdf.pid])\n",
    "tdf = tdf.query('~exclude').copy().drop('exclude', axis=1)\n",
    "print(f'excluding {exclude.sum()} out of {len(exclude)} partipicants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_env(state_rewards):\n",
    "    state_rewards[0] = 0\n",
    "    return make_env(ground_truth=state_rewards)\n",
    "tdf['env'] = tdf.state_rewards.apply(get_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "participants = dict()\n",
    "for i, row in tdf.iterrows():\n",
    "    if row['pid'] in participants.keys():\n",
    "        participants[row['pid']].append((row['env'],row['clicks']))\n",
    "    else:\n",
    "        participants[row['pid']] =[(row['env'],row['clicks'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_errs = np.linspace(0.01,0.25, 25)\n",
    "temp = np.logspace(-5,1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dc_log_likelihood(env, trial, temp, p_error):\n",
    "    done, option_seqs, likelihoods = parse_options(env,trial,t=temp,p_rand=p_error)\n",
    "#     print(option_seqs)\n",
    "#     print(likelihoods)\n",
    "    return np.sum(np.log(likelihoods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-80.192944532067358"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = list(participants.keys())[0]\n",
    "env,trial = participants[p][6]\n",
    "\n",
    "dc_log_likelihood(env, trial, 1, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.081907797999975\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.process_time()\n",
    "for i in range(1000):\n",
    "    dc_log_likelihood(env, trial, 1, 0.01)\n",
    "elapsed =time.process_time() - t \n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96176109299995\n"
     ]
    }
   ],
   "source": [
    "temp, p_error = 1,.01\n",
    "data = participants[p]\n",
    "t = time.process_time()\n",
    "sum(dc_log_likelihood(env, trial, temp, p_error) for env, trial in data)\n",
    "elapsed =time.process_time() - t \n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mle(data):\n",
    "# You can adjust the temperature bounds if you think the MLE\n",
    "# is not in the bounds below. Don't change the p_error bounds.\n",
    "    bounds = [\n",
    "        (1e-5, 1e2),  # temp\n",
    "        (0, .25)  # p_error\n",
    "    ]\n",
    "    def loss(x):\n",
    "        temp, p_error = x\n",
    "        return -sum(dc_log_likelihood(env, trial, temp, p_error)\n",
    "                    for env, trial in data)\n",
    "    res = scipy.optimize.minimize(loss, (1,.01),bounds = bounds)\n",
    "    temp, p_error = res.x\n",
    "    return {'temp': res.x[0], 'p_error': res.x[1], 'logp': -res.fun}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mle_wrap(p):\n",
    "    d = mle(participants[p])\n",
    "    d['participant']:p\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.582908781999777\n",
      "{'temp': 100.0, 'p_error': 0.25, 'logp': -3472.9150719069462}\n"
     ]
    }
   ],
   "source": [
    "mles=dict()\n",
    "p = list(participants.keys())[0]\n",
    "t = time.process_time()\n",
    "mles[p] = mle_wrap(p)\n",
    "elapsed =time.process_time() - t \n",
    "print(elapsed)\n",
    "print(mles[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3472.9150719069462"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dc_log_likelihood(env, trial, 100.0, 0.25) for env, trial in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mles = dict()\n",
    "# for p in participants.keys():\n",
    "#     print(p)\n",
    "#     data = participants[p]\n",
    "#     mles[p] = mle(data)\n",
    "mles = Parallel(n_jobs=20)(delayed(mle_wrap)(p)\n",
    "                           for p in [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('dc_mles',mles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'temp': 100.0, 'p_error': 0.25, 'logp': -3472.9150719069462}], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('dc_mles.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
